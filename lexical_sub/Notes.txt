'''
The Results I am getting:

Part 2: wn_frequency
Total = 298, attempted = 298
precision = 0.098, recall = 0.098
Total with mode 206 attempted 206
precision = 0.136, recall = 0.136


Part 3: wn_simple_lesk
Total = 298, attempted = 298
precision = 0.100, recall = 0.100
Total with mode 206 attempted 206
precision = 0.146, recall = 0.146

Part4: Word2Vec
Total = 298, attempted = 298
precision = 0.115, recall = 0.115
Total with mode 206 attempted 206
precision = 0.170, recall = 0.170

Part 5: BERT
Total = 298, attempted = 298
precision = 0.123, recall = 0.123
Total with mode 206 attempted 206
precision = 0.184, recall = 0.184

For Part 6 I was looking and trying different methods, the one that was an improvement from  the original Bert
was by changing the MASK to the context lemma. It improved the precision by .019 and the.015 respecitively in the gold.trial
tests: Here is my output

part6: Bert_with_lemma_predict
Total = 298, attempted = 298
precision = 0.142, recall = 0.142
Total with mode 206 attempted 206
precision = 0.199, recall = 0.199



'''